# ThinkFirst: 反 AI 沉迷的视觉思考助手

ThinkFirst 是一个旨在对抗“AI 依赖症”的教育实验项目。在这个即时满足的时代，我们拒绝直接给出答案，而是像苏格拉底一样，通过视觉引导和启发式提问，强制用户经历“思考”的过程。

## 核心宗旨
**"Don't just get the answer. Build the answer."**
（不要只获取答案，要去构建答案。）

---

## 核心功能与设计哲学

### 1. 预测优先 (Prediction First)
*   **功能**：当用户提出问题或说“我不知道”时，AI **拒绝**直接给出解释或图片。相反，它会追问一个基础的、启发直觉的问题，迫使用户先进行猜想。
*   **交互流程**：
    1.  **拒绝回答**：避免一次性输出全部答案。
    2.  **视觉线索**：通过生成一张图片（或数学模型），引导用户去观察、猜测其内容。
    3.  **用户反馈**：用户告诉 AI 自己的联想或猜测。
    4.  **迭代引导**：AI 判断用户的理解程度，给出下一步的视觉线索，直到用户完成整个思考过程。
    *例如：如果用户问“sin30度是多少”，AI 不会直接说 0.5，而是可能会展示一个边长为 2 的等边三角形被切成两半的图形，问用户“这让你想到了什么？”*
*   **为什么符合宗旨**：打破“伸手党”习惯。我们认为这种方式不仅对毫无背景知识的用户很友好，也能达到鼓励独立思考、戒掉 AI 依赖的目的。

### 2. 自适应视觉引擎 (Adaptive Visual Engine)
*   **功能**：根据问题的认知类型，自动切换视觉工具：
    *   **好奇心/自然类**（如“天为什么是蓝的”）：生成**写实/电影级**图像，唤起对真实世界的观察。
    *   **数学/逻辑类**（如“函数单调性”）：调用 **Desmos 图形计算器**，生成动态数学模型。
*   **为什么符合宗旨**：不同的知识需要不同的思维载体。我们将抽象逻辑具象化，不是为了替代思考，而是为了降低“认知负荷”，让用户能专注于核心逻辑的推演。

### 3. 视觉隐喻 (Visual Metaphor)
*   **功能**：AI 生成的图片不是教科书式的插图，而是包含线索的“视觉谜题”。用户必须观察图片细节，结合引导语，自己推导出结论。
*   **为什么符合宗旨**：将“阅读答案”转化为“侦探解谜”。用户必须主动调动注意力去**观察**和**关联**，这是深度思考的必要条件。

### 4. 动态逻辑闭环 (Dynamic Logical Closure)
*   **功能**：不再预设固定的问答轮次。AI 会实时评估用户是否真正理解了核心逻辑链条。只有当逻辑完全闭环时，探索才会结束。
*   **为什么符合宗旨**：思考不是走过场。我们追求的是真正的“顿悟”（Aha Moment），而不是机械地完成任务。

### 5. 结论归属权 (Ownership of Synthesis)
*   **功能**：在对话结束时，**禁止 AI 自动总结**。系统会强制要求用户用自己的话概括最终结论或定义，AI 仅作为点评者出现。
*   **为什么符合宗旨**：防止“虚假学习感”。只有能用自己的语言复述出来的知识，才真正属于用户。

### 6. 多模态交互 (Multimodal Interaction)
*   **功能**：支持用户上传图片，AI 会对其进行深度视觉分析（基于 Qwen2-VL），并将其融入对话上下文。
*   **为什么符合宗旨**：鼓励用户从现实生活中取材。思考不应局限于屏幕，更应连接现实世界。

---

## 技术栈亮点
*   **大模型大脑**：DeepSeek V3 (负责逻辑推理与苏格拉底式引导)
*   **视觉生成**：SiliconFlow Flux.1-dev (负责高质量图像生成)
*   **视觉理解**：Qwen2-VL (负责用户图片分析)
*   **数学引擎**：Desmos API (负责动态数学可视化)
*   **后端框架**：Django 4.2 + Python 3.9
