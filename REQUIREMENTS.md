# 项目需求文档：ThinkFirst (SiliconFlow 重构版)

## 1. 项目概述
**项目名称**：ThinkFirst
**核心理念**：通过“看图说话”式的互动流程，强制用户通过解释 AI 生成的视觉线索来构建自己的答案，培养独立思考与联想能力。
**技术栈**：
- **后端**：Django (Python)
- **AI 基础设施**：SiliconFlow API (LLM: Qwen/DeepSeek, Image Gen: Flux.1/Stable Diffusion 3)
- **数据库**：SQLite
- **前端**：Django Templates + TailwindCSS

## 2. 核心业务流程 (Updated)

### 2.1 阶段一：初始探针 (Initial Probe)
1.  **用户提问**：用户输入想要解决的问题。
2.  **AI 策略路由**：
    *   AI 询问：“关于这个问题，你现在有什么初步的想法或直觉吗？”
    *   **分支 A (有想法)**：用户输入想法 -> AI 记录并基于此生成第一张引导图。
    *   **分支 B (无想法)**：用户表示不知道 -> AI 基于问题核心概念生成第一张引导图（冷启动）。

### 2.2 阶段二：视觉互动引导 (Visual Socratic Loop)
这是一个类似“互动视频”或“解谜游戏”的过程：
1.  **AI 生成线索图**：AI 基于当前思维路径的下一步，生成一张**不带文字解释**的抽象或具象图片。
2.  **用户解码**：用户必须观察图片，并用文字/语音解释：“这张图跟我的问题有什么关系？”
3.  **AI 验证与反馈**：
    *   **通过**：用户的解释触及了核心逻辑 -> 进入下一环（生成下一张图）。
    *   **偏差**：用户的解释偏离 -> AI 给出简短提示（Text Hint），要求用户重新观察图片或修正思路。
    *   **失败**：多次尝试失败 -> AI 揭示此图含义，并生成一张更简单的图。
4.  **循环**：重复上述步骤，直到问题被完整构建解决。

### 2.3 阶段三：最终回顾 (Review)
- **生成报告**：展示所有的图片序列和用户的解释过程。
- **思维路径图**：可视化用户的思考跳跃。
- **导师建议**：针对用户“看图联想”能力的评价（例如：是否擅长类比，是否容易陷入细节）。

## 3. 功能模块详细需求

### 3.1 AI 服务层 (SiliconFlow)
- **LLM 接口**：用于对话控制、意图识别、图片提示词(Prompt)生成、用户回答验证。
    - 模型推荐：`Qwen2.5-72B-Instruct` 或 `DeepSeek-V3`。
- **Image Gen 接口**：用于实时生成引导图片。
    - 模型推荐：`black-forest-labs/FLUX.1-schnell` (速度快，质量高)。

### 3.2 数据库模型变更
- **Conversation**：增加状态字段（`initial_probe`, `visual_loop`, `completed`）。
- **Interaction**：增加 `ai_image_url` (AI 生成的图), `image_prompt` (生成图的提示词), `user_interpretation` (用户对图的解读), `is_passed` (是否通过验证)。

## 4. 界面交互
- **聊天区**：
    - 显著展示 AI 生成的大图。
    - 用户的输入框变为“我看到了什么...”或“这不仅意味着...”。
- **状态指示**：清晰展示当前处于第几关/第几张图。

## 5. 配置要求
- `SILICONFLOW_API_KEY`
